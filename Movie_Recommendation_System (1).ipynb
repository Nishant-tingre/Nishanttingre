{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I developed a sophisticated movie recommendation system utilizing The Movie Database (TMDb) API to efficiently retrieve and preprocess movie data, incorporating genres, overviews, and user comments for personalized suggestions. Using techniques such as TF-IDF Vectorizer and cosine similarity, I created a content-based filtering algorithm to accurately measure movie similarity, enhancing the user experience by providing tailored movie recommendations. Additionally, this project includes a Google Colab implementation that mounts Google Drive, imports necessary libraries like pandas, requests, and Gradio, and integrates a Gradio interface to interactively recommend movies and display user reviews based on individual preferences"
      ],
      "metadata": {
        "id": "QUduQPR8DrWU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0FNuLHQPHw8",
        "outputId": "fda04d86-c752-4ef0-d32d-288399918795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Failed to fetch data for movie ID 1: 404\n",
            "Failed to fetch data for movie ID 4: 404\n",
            "Failed to fetch data for movie ID 7: 404\n",
            "Failed to fetch data for movie ID 10: 404\n",
            "Failed to fetch data for movie ID 23: 404\n",
            "Failed to fetch data for movie ID 29: 404\n",
            "Failed to fetch data for movie ID 30: 404\n",
            "Failed to fetch data for movie ID 31: 404\n",
            "Failed to fetch data for movie ID 32: 404\n",
            "Failed to fetch data for movie ID 34: 404\n",
            "Failed to fetch data for movie ID 36: 404\n",
            "Failed to fetch data for movie ID 37: 404\n",
            "Failed to fetch data for movie ID 39: 404\n",
            "Failed to fetch data for movie ID 40: 404\n",
            "Failed to fetch data for movie ID 41: 404\n",
            "Failed to fetch data for movie ID 42: 404\n",
            "Failed to fetch data for movie ID 43: 404\n",
            "Failed to fetch data for movie ID 44: 404\n",
            "Failed to fetch data for movie ID 45: 404\n",
            "Failed to fetch data for movie ID 46: 404\n",
            "Failed to fetch data for movie ID 47: 404\n",
            "Failed to fetch data for movie ID 48: 404\n",
            "Failed to fetch data for movie ID 49: 404\n",
            "Failed to fetch data for movie ID 50: 404\n",
            "Failed to fetch data for movie ID 51: 404\n",
            "Failed to fetch data for movie ID 52: 404\n",
            "Failed to fetch data for movie ID 53: 404\n",
            "Failed to fetch data for movie ID 54: 404\n",
            "Failed to fetch data for movie ID 56: 404\n",
            "Failed to fetch data for movie ID 57: 404\n",
            "Failed to fetch data for movie ID 60: 404\n",
            "Failed to fetch data for movie ID 61: 404\n",
            "Failed to fetch data for movie ID 72: 404\n",
            "Failed to fetch data for movie ID 84: 404\n",
            "Fetched 65 movies.\n",
            "Data with reviews saved to /content/drive/My Drive/tmdb_movies_with_reviews.csv!\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# TMDb API Key\n",
        "api_key = '5552246a1142026c763b3f08f23dea10'\n",
        "\n",
        "# Function to fetch movie data by ID\n",
        "def fetch_movie_data(movie_id):\n",
        "    url = f'https://api.themoviedb.org/3/movie/{movie_id}?api_key={api_key}'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f\"Failed to fetch data for movie ID {movie_id}: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "# Function to fetch multiple movies\n",
        "def fetch_multiple_movies(movie_ids):\n",
        "    movies = []\n",
        "    for movie_id in movie_ids:\n",
        "        movie_data = fetch_movie_data(movie_id)\n",
        "        if movie_data:\n",
        "            movies.append(movie_data)\n",
        "        time.sleep(0.25)  # Rate-limiting to avoid API overload\n",
        "    return movies\n",
        "\n",
        "# Function to fetch reviews for a movie\n",
        "def fetch_movie_reviews(movie_id):\n",
        "    url = f'https://api.themoviedb.org/3/movie/{movie_id}/reviews?api_key={api_key}'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        reviews = response.json().get('results', [])\n",
        "        return ' '.join([review['content'] for review in reviews[:3]])  # Concatenate top 3 reviews\n",
        "    else:\n",
        "        print(f\"Failed to fetch reviews for movie ID {movie_id}: {response.status_code}\")\n",
        "        return \"No reviews available.\"\n",
        "\n",
        "# Add reviews to the movie data\n",
        "def preprocess_movie_data_with_reviews(movies):\n",
        "    movie_list = []\n",
        "    for movie in movies:\n",
        "        if all(key in movie for key in ['id', 'title', 'genres', 'popularity', 'vote_average', 'overview']):\n",
        "            reviews = fetch_movie_reviews(movie['id'])  # Fetch reviews for the movie\n",
        "            movie_info = {\n",
        "                'id': movie['id'],\n",
        "                'title': movie['title'],\n",
        "                'genres': [genre['name'] for genre in movie['genres']],\n",
        "                'popularity': movie['popularity'],\n",
        "                'vote_average': movie['vote_average'],\n",
        "                'overview': movie['overview'],\n",
        "                'reviews': reviews,\n",
        "            }\n",
        "            movie_list.append(movie_info)\n",
        "    return pd.DataFrame(movie_list)\n",
        "\n",
        "# Fetch data for movie IDs 1 to 50 (or any range you want)\n",
        "movie_ids = range(1, 100)  # Adjust range as needed\n",
        "movies = fetch_multiple_movies(movie_ids)  # Fetch the movies\n",
        "\n",
        "# Check if movies were fetched correctly\n",
        "if not movies:\n",
        "    print(\"No movies fetched. Check the API key and movie IDs.\")\n",
        "else:\n",
        "    print(f\"Fetched {len(movies)} movies.\")\n",
        "\n",
        "# Create and save the DataFrame with reviews\n",
        "df = preprocess_movie_data_with_reviews(movies)  # Now `movies` is defined\n",
        "output_path = '/content/drive/My Drive/tmdb_movies_with_reviews.csv'\n",
        "df.to_csv(output_path, index=False)  # Save to file\n",
        "print(f\"Data with reviews saved to {output_path}!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movies_with_reviews(movie_title, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommend movies based on the given movie title and include user reviews.\n",
        "\n",
        "    Args:\n",
        "        movie_title (str): Title of the movie to find recommendations for.\n",
        "        top_n (int): Number of recommendations to return.\n",
        "\n",
        "    Returns:\n",
        "        List of recommended movie titles with reviews or an error message if not found.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Find the index of the movie\n",
        "        idx = df[df['title'].str.lower() == movie_title.lower()].index[0]\n",
        "        # Get similarity scores for all movies\n",
        "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "        # Sort movies by similarity score (descending)\n",
        "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "        # Get indices of top_n most similar movies (excluding the input movie itself)\n",
        "        movie_indices = [i[0] for i in sim_scores[1:top_n + 1]]\n",
        "        # Return the recommended movie titles and their reviews\n",
        "        recommendations = []\n",
        "        for i in movie_indices:\n",
        "            recommendations.append({\n",
        "                'title': df['title'].iloc[i],\n",
        "                'reviews': df['reviews'].iloc[i]\n",
        "            })\n",
        "        return recommendations\n",
        "    except IndexError:\n",
        "        return f\"Movie '{movie_title}' not found in the dataset.\"\n"
      ],
      "metadata": {
        "id": "XQEOrjUyPULv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio Interface with Reviews\n",
        "!pip install gradio # Install gradio library\n",
        "import gradio as gr # Import gradio and alias as 'gr'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61uAObKEQk0z",
        "outputId": "efcf3497-0da1-42ae-a286-a2f7513f5600"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.13.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.6.0 (from gradio)\n",
            "  Downloading gradio_client-1.6.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.5)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.13.0-py3-none-any.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.6.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.7 ffmpy-0.5.0 gradio-5.13.0 gradio-client-1.6.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.2 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gradio as gr\n",
        "\n",
        "# TMDb API Key\n",
        "api_key = '5552246a1142026c763b3f08f23dea10'\n",
        "\n",
        "# Function to fetch movie data by ID\n",
        "def fetch_movie_data(movie_id):\n",
        "    url = f'https://api.themoviedb.org/3/movie/{movie_id}?api_key={api_key}'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Function to fetch multiple movies\n",
        "def fetch_multiple_movies(movie_ids):\n",
        "    movies = []\n",
        "    for movie_id in movie_ids:\n",
        "        movie_data = fetch_movie_data(movie_id)\n",
        "        if movie_data:\n",
        "            movies.append(movie_data)\n",
        "        time.sleep(0.25)  # Rate-limiting to avoid API overload\n",
        "    return movies\n",
        "\n",
        "# Function to fetch reviews for a movie\n",
        "def fetch_movie_reviews(movie_id):\n",
        "    url = f'https://api.themoviedb.org/3/movie/{movie_id}/reviews?api_key={api_key}'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        reviews = response.json().get('results', [])\n",
        "        return ' '.join([review['content'] for review in reviews[:3]])  # Top 3 reviews\n",
        "    else:\n",
        "        return \"No reviews available.\"\n",
        "\n",
        "# Add reviews to the movie data\n",
        "def preprocess_movie_data_with_reviews(movies):\n",
        "    movie_list = []\n",
        "    for movie in movies:\n",
        "        if all(key in movie for key in ['id', 'title', 'genres', 'popularity', 'vote_average', 'overview']):\n",
        "            reviews = fetch_movie_reviews(movie['id'])\n",
        "            movie_info = {\n",
        "                'id': movie['id'],\n",
        "                'title': movie['title'],\n",
        "                'genres': [genre['name'] for genre in movie['genres']],\n",
        "                'popularity': movie['popularity'],\n",
        "                'vote_average': movie['vote_average'],\n",
        "                'overview': movie['overview'],\n",
        "                'reviews': reviews,\n",
        "            }\n",
        "            movie_list.append(movie_info)\n",
        "    return pd.DataFrame(movie_list)\n",
        "\n",
        "# Fetch data for movie IDs 1 to 50\n",
        "movie_ids = range(1, 50)\n",
        "movies = fetch_multiple_movies(movie_ids)\n",
        "\n",
        "# Check movies\n",
        "if not movies:\n",
        "    print(\"No movies fetched.\")\n",
        "else:\n",
        "    df = preprocess_movie_data_with_reviews(movies)\n",
        "    output_path = '/content/drive/My Drive/tmdb_movies_with_reviews.csv'\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"Data saved to {output_path}!\")\n",
        "\n",
        "# Create a similarity matrix\n",
        "def create_similarity_matrix(df):\n",
        "    df['combined'] = df['genres'].astype(str) + \" \" + df['overview']\n",
        "    vectorizer = CountVectorizer()\n",
        "    count_matrix = vectorizer.fit_transform(df['combined'])\n",
        "    return cosine_similarity(count_matrix)\n",
        "\n",
        "cosine_sim = create_similarity_matrix(df)\n",
        "\n",
        "# Recommend movies\n",
        "def recommend_movies_with_reviews(movie_title, top_n=5):\n",
        "    try:\n",
        "        idx = df[df['title'].str.lower() == movie_title.lower()].index[0]\n",
        "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "        movie_indices = [i[0] for i in sim_scores[1:top_n + 1]]\n",
        "        recommendations = []\n",
        "        for i in movie_indices:\n",
        "            recommendations.append({\n",
        "                'title': df['title'].iloc[i],\n",
        "                'reviews': df['reviews'].iloc[i]\n",
        "            })\n",
        "        return recommendations\n",
        "    except IndexError:\n",
        "        return f\"Movie '{movie_title}' not found in the dataset.\"\n",
        "\n",
        "# Gradio Interface\n",
        "def gradio_recommend_with_reviews(movie_title):\n",
        "    recommendations = recommend_movies_with_reviews(movie_title)\n",
        "    if isinstance(recommendations, list):\n",
        "        output = f\"Movies similar to '{movie_title}':\\n\"\n",
        "        for rec in recommendations:\n",
        "            output += f\"\\nTitle: {rec['title']}\\nReviews: {rec['reviews']}\\n\"\n",
        "        return output\n",
        "    else:\n",
        "        return recommendations\n",
        "\n",
        "# Create and Launch Gradio Interface\n",
        "interface = gr.Interface(\n",
        "    fn=gradio_recommend_with_reviews,\n",
        "    inputs=gr.Textbox(label=\"Enter a Movie Title\"),\n",
        "    outputs=gr.Textbox(label=\"Recommended Movies with Reviews\"),\n",
        "    title=\"Movie Recommendation System\",\n",
        "    description=\"Enter a movie title to get recommendations and reviews.\"\n",
        ")\n",
        "\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "LWvzlYDcRZxO",
        "outputId": "346704d0-8a3d-42bc-9446-69e471bdcb35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Data saved to /content/drive/My Drive/tmdb_movies_with_reviews.csv!\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4ae39630145554a560.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4ae39630145554a560.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s8joM0k-_ROu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}