{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0ESsKoXPeor"
      },
      "source": [
        "**Problem Statement:**\n",
        "\n",
        "Case Study: Mental Health Status Prediction for Clinical Patients using Natural Language Processing (NLP)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  **Background:**\n",
        "\n",
        "  Mental health disorders such as anxiety, depression, and stress affect millions of people worldwide, yet many patients do not receive the proper diagnosis or treatment in time due to the subtle nature of symptoms and the complexity of mental health assessments. Mental health professionals often rely on self-reported statements from patients to understand their emotional state, but manual interpretation of these statements can be time-consuming and prone to inconsistencies.\n",
        "\n",
        "  To address this issue, healthcare providers are exploring AI-based solutions that can assist clinicians by automating parts of the diagnostic process through Natural Language Processing (NLP) techniques. By analyzing the language used by patients in their statements, it is possible to detect underlying mental health conditions and flag patients who may need further evaluation or treatment.\n",
        "\n",
        "\n",
        "**Business Challenge:**\n",
        "\n",
        "A leading healthcare provider wants to implement an AI-based system to help its mental health professionals better diagnose and monitor the mental well-being of their patients. The system will analyze text statements provided by patients during consultations, therapy sessions, or through online surveys. These statements could include descriptions of how patients are feeling, their emotional state, or details of their daily life.\n",
        "\n",
        "The goal of the system is to classify these statements into mental health categories such as \"Anxiety,\" \"Depression,\" \"Normal,\" and other relevant conditions. This will allow clinicians to quickly identify patients at risk and take timely action. Such a system can also be integrated into telemedicine platforms to monitor patients remotely and offer additional layers of support.\n",
        "\n",
        "\n",
        "\n",
        "**Objective:**\n",
        "\n",
        "The objective of this project is to develop a deep learning-based NLP model that can accurately predict the mental health status of patients based on their written or spoken statements. The model will assist clinicians by automatically classifying patients into categories such as \"Anxiety,\" \"Depression,\" \"Normal,\" \"Stress,\" and other related conditions. This system will help healthcare professionals prioritize patients needing immediate care and ensure timely interventions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qkbv-RpGQTXO"
      },
      "outputs": [],
      "source": [
        "import zipfile  # Import the zipfile module to work with ZIP files\n",
        "zip_ref = zipfile.ZipFile('/content/archive (21).zip', 'r')\n",
        "# Extract all contents of the ZIP file into the directory '/content'\n",
        "zip_ref.extractall('/content')\n",
        "# Close the opened ZIP file\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMKt2JujRUzK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE2lvah8RdYF"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/Combined Data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfZ7nA1IRktT"
      },
      "outputs": [],
      "source": [
        "df=df.drop(columns=['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "S8j8PXYNRr0-",
        "outputId": "ddaeb386-9ba2-43ed-d8da-dc5d02b5dc63"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>statement</th>\n",
              "      <td>362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "statement    362\n",
              "status         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6HwClsRpSGks",
        "outputId": "43950d54-1754-4a87-c25c-9c31e5f03fa1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "0",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5c059df3-5299-4504-9023-9943829068ee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1539</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2448</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52838</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52870</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52936</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53010</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53031</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>362 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c059df3-5299-4504-9023-9943829068ee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c059df3-5299-4504-9023-9943829068ee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c059df3-5299-4504-9023-9943829068ee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-163a13c0-e9ab-462e-babb-5d8ff4025850\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-163a13c0-e9ab-462e-babb-5d8ff4025850')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-163a13c0-e9ab-462e-babb-5d8ff4025850 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      statement   status\n",
              "293         NaN  Anxiety\n",
              "572         NaN  Anxiety\n",
              "595         NaN  Anxiety\n",
              "1539        NaN   Normal\n",
              "2448        NaN   Normal\n",
              "...         ...      ...\n",
              "52838       NaN  Anxiety\n",
              "52870       NaN  Anxiety\n",
              "52936       NaN  Anxiety\n",
              "53010       NaN  Anxiety\n",
              "53031       NaN  Anxiety\n",
              "\n",
              "[362 rows x 2 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['statement'].isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzRj5xqOS4Np"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "zpkrZfDBSl2z",
        "outputId": "12b4c7ac-439a-4b86-ce85-3f57ea0a3cd6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>statement</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "statement    0\n",
              "status       0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ytzHBiiGS9uc",
        "outputId": "3cdf9533-6393-4f51-ccc4-166841e74b5c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 52681,\n  \"fields\": [\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 51073,\n        \"samples\": [\n          \"he's been a chain smoker for 30 years.\",\n          \"Dependence on therapist I attend IOP groups and individual therapy sessions at the same place, my therapist who I have worked with on and off for a year and a couple months just told me today that she is leaving soon and I am heartbroken. I love my therapist and I don't know how I am going to keep progressing without her. There will be a replacement for her but idk what to do, I don't want a different therapist. :(\",\n          \"These feelings constantly come back. Someone from my past that hurt me came back a month ago and once again disrespected me and i just feel like shit. Idk why these feelings keep resurfacing but it just hurts. I do not want to be over dramatic but Its hurts when you were nothing but loving/kind to someone and they disrespect you. I just hate feeling like this, feeling like i cannot trust anyone or that no one would ever truly love me unless i have something to offer. I am always worried about my looks and its just making me depressed. I really do not feel like i fit in with the world I am just here. Idk what my next step should be to get help but I am really going through it. (Yes I am in therapy) but how do i help myself ? I have been depressed/anxious for years and most day i do not even leave my house. But nobody around me seems to care and honestly I am tired of feeling this way. But at the same time i do not want to give up on myself bc i feel like I am here to be somebody great. I am just trying to find my way right now. It keeps coming back\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Anxiety\",\n          \"Normal\",\n          \"Bipolar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0025c192-df06-4fd0-8d32-557fb389d03b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>oh my gosh</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I've shifted my focus to something else but I'...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'm restless and restless, it's been a month n...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53038</th>\n",
              "      <td>Nobody takes me seriously I’ve (24M) dealt wit...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53039</th>\n",
              "      <td>selfishness  \"I don't feel very good, it's lik...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53040</th>\n",
              "      <td>Is there any way to sleep better? I can't slee...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53041</th>\n",
              "      <td>Public speaking tips? Hi, all. I have to give ...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53042</th>\n",
              "      <td>I have really bad door anxiety! It's not about...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52681 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0025c192-df06-4fd0-8d32-557fb389d03b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0025c192-df06-4fd0-8d32-557fb389d03b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0025c192-df06-4fd0-8d32-557fb389d03b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-610bfff2-411d-4b0b-b5ef-9b152e75fc17\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-610bfff2-411d-4b0b-b5ef-9b152e75fc17')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-610bfff2-411d-4b0b-b5ef-9b152e75fc17 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4eef89ef-336c-4db6-b06a-200a6f3eaba4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4eef89ef-336c-4db6-b06a-200a6f3eaba4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               statement   status\n",
              "0                                             oh my gosh  Anxiety\n",
              "1      trouble sleeping, confused mind, restless hear...  Anxiety\n",
              "2      All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
              "3      I've shifted my focus to something else but I'...  Anxiety\n",
              "4      I'm restless and restless, it's been a month n...  Anxiety\n",
              "...                                                  ...      ...\n",
              "53038  Nobody takes me seriously I’ve (24M) dealt wit...  Anxiety\n",
              "53039  selfishness  \"I don't feel very good, it's lik...  Anxiety\n",
              "53040  Is there any way to sleep better? I can't slee...  Anxiety\n",
              "53041  Public speaking tips? Hi, all. I have to give ...  Anxiety\n",
              "53042  I have really bad door anxiety! It's not about...  Anxiety\n",
              "\n",
              "[52681 rows x 2 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6xNXYF4TW0V"
      },
      "outputs": [],
      "source": [
        "#Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uv9KxhlGT9ja"
      },
      "outputs": [],
      "source": [
        "df['statement']=df['statement'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppxFpWTyU2UW"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHx1cpqxUDC9"
      },
      "outputs": [],
      "source": [
        "def remove_punc(text):\n",
        "  return re.sub('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]','',text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQwHIDUaU5O0"
      },
      "outputs": [],
      "source": [
        "df['statement']=df['statement'].apply(remove_punc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZxp21dUVBuS"
      },
      "outputs": [],
      "source": [
        "chat_words={\n",
        "  \"LOL\": \"Laugh Out Loud\",\n",
        "  \"BRB\": \"Be Right Back\",\n",
        "  \"OMG\": \"Oh My God\",\n",
        "  \"TTYL\": \"Talk To You Later\",\n",
        "  \"IDK\": \"I Don't Know\",\n",
        "  \"FYI\": \"For Your Information\",\n",
        "  \"BTW\": \"By The Way\",\n",
        "  \"ROFL\": \"Rolling On the Floor Laughing\",\n",
        "  \"SMH\": \"Shaking My Head\",\n",
        "  \"IMO\": \"In My Opinion\",\n",
        "  \"IMHO\": \"In My Humble Opinion\",\n",
        "  \"ICYMI\": \"In Case You Missed It\",\n",
        "  \"DM\": \"Direct Message\",\n",
        "  \"GTG\": \"Got To Go\",\n",
        "  \"G2G\": \"Got To Go\",\n",
        "  \"FTW\": \"For The Win\",\n",
        "  \"AFK\": \"Away From Keyboard\",\n",
        "  \"NP\": \"No Problem\",\n",
        "  \"AMA\": \"Ask Me Anything\",\n",
        "  \"FOMO\": \"Fear Of Missing Out\",\n",
        "  \"OOTD\": \"Outfit Of The Day\",\n",
        "  \"TL;DR\": \"Too Long; Didn't Read\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoopRGx1VleZ"
      },
      "outputs": [],
      "source": [
        "def chatword_rep(text):\n",
        "  l=[]\n",
        "  for i in text.split():\n",
        "    if i in chat_words.keys():\n",
        "      l.append(chat_words[i])\n",
        "    else:\n",
        "      l.append(i)\n",
        "  return ' '.join(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "HulTR7SwaGcz",
        "outputId": "a3935a52-c9dd-4fc7-ac5a-c8601929af17"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>oh my gosh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>trouble sleeping confused mind restless heart ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>all wrong back off dear forward doubt stay in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ive shifted my focus to something else but im ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>im restless and restless its been a month now ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53038</th>\n",
              "      <td>nobody takes me seriously i’ve 24m dealt with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53039</th>\n",
              "      <td>selfishness i dont feel very good its like i d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53040</th>\n",
              "      <td>is there any way to sleep better i cant sleep ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53041</th>\n",
              "      <td>public speaking tips hi all i have to give a p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53042</th>\n",
              "      <td>i have really bad door anxiety its not about b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52681 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0                                               oh my gosh\n",
              "1        trouble sleeping confused mind restless heart ...\n",
              "2        all wrong back off dear forward doubt stay in ...\n",
              "3        ive shifted my focus to something else but im ...\n",
              "4        im restless and restless its been a month now ...\n",
              "                               ...                        \n",
              "53038    nobody takes me seriously i’ve 24m dealt with ...\n",
              "53039    selfishness i dont feel very good its like i d...\n",
              "53040    is there any way to sleep better i cant sleep ...\n",
              "53041    public speaking tips hi all i have to give a p...\n",
              "53042    i have really bad door anxiety its not about b...\n",
              "Name: statement, Length: 52681, dtype: object"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['statement'].apply(chatword_rep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL8kAihfa2js"
      },
      "outputs": [],
      "source": [
        "def remove_extra(text):\n",
        "  return re.sub('  ','',text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrNMNgQDaXAH"
      },
      "outputs": [],
      "source": [
        "df['statement']=df['statement'].apply(remove_extra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1c-YEDShblp",
        "outputId": "316b3086-c4e2-4102-892e-b9f110b52c90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nDuazz-hucz"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tG1hG6YIiebL"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAiIHQ4SiGDL"
      },
      "outputs": [],
      "source": [
        "def stop_word(text):\n",
        " l2=[]\n",
        " for i in text.split():\n",
        "  if i in stop_words:\n",
        "    l2.append('')\n",
        "  else:\n",
        "    l2.append(i)\n",
        " return ' '.join(l2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOeQzqclh3pC"
      },
      "outputs": [],
      "source": [
        "df['statement']=df['statement'].apply(stop_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z3pRM8FmF97",
        "outputId": "998ff846-e19c-4118-bae9-2c90b3d609a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['statement'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOhlz8sThy5-",
        "outputId": "9211356d-177f-4cb7-e4e8-7cbfc5d251d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from nltk import sent_tokenize,word_tokenize\n",
        "from gensim.utils import simple_preprocess\n",
        "data = []\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "for doc in df['statement']:\n",
        "    raw_sent = word_tokenize(doc)\n",
        "    for sent in raw_sent:\n",
        "        data.append(simple_preprocess(sent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNRdVb2_xGsy"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['status'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4slxo1FUKul",
        "outputId": "78655b67-71f1-4bf9-e07b-b50ef4bac715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "7i6zbY50Z8o6",
        "outputId": "8e5491be-9f0e-4c7a-ad0a-aaef11f2b4ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-c071c29a6c8e>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'statement'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mcleaned_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_and_lemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_doc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Collect tokenized and lemmatized sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-c071c29a6c8e>\u001b[0m in \u001b[0;36mtokenize_and_lemmatize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Function to tokenize and lemmatize the text (done after all preprocessing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_and_lemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Tokenize the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mlemmatized_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Apply lemmatization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlemmatized_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     return [\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     return [\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/destructive.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENDING_QUOTES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONTRACTIONS2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import zipfile  # Import the zipfile module to work with ZIP files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import gensim\n",
        "from nltk import word_tokenize, WordNetLemmatizer\n",
        "from gensim.utils import simple_preprocess\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Load and extract ZIP file\n",
        "zip_ref = zipfile.ZipFile('/content/archive (21).zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('/content/Combined Data.csv')\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "df.dropna(inplace=True)\n",
        "df['statement'] = df['statement'].str.lower()\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')  # Download wordnet for lemmatization\n",
        "\n",
        "# Initialize lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to remove punctuation\n",
        "def remove_punc(text):\n",
        "    return re.sub('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]', '', text)\n",
        "\n",
        "# Preprocess: remove punctuation\n",
        "df['statement'] = df['statement'].apply(remove_punc)\n",
        "\n",
        "# Function to tokenize and lemmatize the text (done after all preprocessing)\n",
        "def tokenize_and_lemmatize(text):\n",
        "    tokens = word_tokenize(text)  # Tokenize the text\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Apply lemmatization\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Apply tokenization and lemmatization after cleaning\n",
        "data = []\n",
        "for doc in df['statement']:\n",
        "    cleaned_doc = tokenize_and_lemmatize(doc)\n",
        "    data.append(cleaned_doc)  # Collect tokenized and lemmatized sentences\n",
        "\n",
        "# Create and train the Word2Vec model\n",
        "model = gensim.models.Word2Vec(\n",
        "    sentences=data,\n",
        "    vector_size=50,  # Choose an appropriate vector size\n",
        "    window=10,\n",
        "    min_count=2,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Function to get document vectors\n",
        "def document_vector(doc):\n",
        "    doc = [word for word in word_tokenize(doc) if word in model.wv.index_to_key]\n",
        "    if len(doc) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "    else:\n",
        "        return np.mean(model.wv[doc], axis=0)\n",
        "\n",
        "# Generate document vectors\n",
        "X = []\n",
        "for doc in tqdm(df['statement']):\n",
        "    X.append(document_vector(doc))\n",
        "\n",
        "# Convert X to numpy array and reshape for LSTM\n",
        "X = np.array(X).reshape(len(X), 1, 50)  # Shape it for LSTM (samples, timesteps, features)\n",
        "\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['status'])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Fit SMOTE to the training data\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check the new class distribution\n",
        "print(f\"Original class distribution: {Counter(y_train)}\")\n",
        "print(f\"New class distribution after SMOTE: {Counter(y_train_smote)}\")\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model1 = Sequential()\n",
        "model1.add(LSTM(50, input_shape=(1, 50), return_sequences=False))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(7, activation='softmax'))  # Adjust based on number of classes\n",
        "model1.summary()\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(loss='sparse_categorical_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Define the checkpoint callback\n",
        "checkpoint = ModelCheckpoint(filepath='/content/model1_best.keras',\n",
        "                             monitor='val_accuracy',\n",
        "                             save_best_only=True,\n",
        "                             verbose=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKln32D9UI_D"
      },
      "outputs": [],
      "source": [
        "import zipfile  # Import the zipfile module to work with ZIP files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import gensim\n",
        "from nltk import word_tokenize, WordNetLemmatizer, download, corpus\n",
        "from gensim.utils import simple_preprocess\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Load and extract ZIP file\n",
        "zip_ref = zipfile.ZipFile('/content/archive (21).zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('/content/Combined Data.csv')\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "df.dropna(inplace=True)\n",
        "df['statement'] = df['statement'].str.lower()\n",
        "\n",
        "# Download NLTK resources\n",
        "download('punkt')\n",
        "download('wordnet')  # Download wordnet for lemmatization\n",
        "download('stopwords')  # Download stopwords\n",
        "\n",
        "# Initialize lemmatizer and stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stopwords = set(corpus.stopwords.words('english'))\n",
        "\n",
        "# Function to remove punctuation\n",
        "def remove_punc(text):\n",
        "    return re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "# Function to remove extra spaces\n",
        "def remove_extra_spaces(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stopwords]\n",
        "\n",
        "# Function to handle chatwords (optional: add more replacements if needed)\n",
        "def handle_chatwords(text):\n",
        "    replacements= {\n",
        "        \"u\": \"you\",\n",
        "        \"r\": \"are\",\n",
        "        \"ur\": \"your\",\n",
        "        \"cuz\": \"because\",\n",
        "        \"pls\": \"please\",\n",
        "        \"thx\": \"thanks\",\n",
        "        \"LOL\": \"Laugh Out Loud\",\n",
        "        \"BRB\": \"Be Right Back\",\n",
        "        \"OMG\": \"Oh My God\",\n",
        "        \"TTYL\": \"Talk To You Later\",\n",
        "        \"IDK\": \"I Don't Know\",\n",
        "        \"FYI\": \"For Your Information\",\n",
        "        \"BTW\": \"By The Way\",\n",
        "        \"ROFL\": \"Rolling On the Floor Laughing\",\n",
        "        \"SMH\": \"Shaking My Head\",\n",
        "        \"IMO\": \"In My Opinion\",\n",
        "        \"IMHO\": \"In My Humble Opinion\",\n",
        "        \"ICYMI\": \"In Case You Missed It\",\n",
        "        \"DM\": \"Direct Message\",\n",
        "        \"GTG\": \"Got To Go\",\n",
        "        \"G2G\": \"Got To Go\",\n",
        "        \"FTW\": \"For The Win\",\n",
        "        \"AFK\": \"Away From Keyboard\",\n",
        "        \"NP\": \"No Problem\",\n",
        "        \"AMA\": \"Ask Me Anything\",\n",
        "        \"FOMO\": \"Fear Of Missing Out\",\n",
        "        \"OOTD\": \"Outfit Of The Day\",\n",
        "        \"TL;DR\": \"Too Long; Didn't Read\"\n",
        "          }\n",
        "    for chatword, replacement in replacements.items():\n",
        "        text = text.replace(chatword, replacement)\n",
        "    return text\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lower case\n",
        "    text = remove_punc(text)  # Remove punctuation\n",
        "    text = handle_chatwords(text)  # Handle chat words\n",
        "    text = remove_extra_spaces(text)  # Remove extra spaces\n",
        "    tokens = word_tokenize(text)  # Tokenize\n",
        "    tokens = remove_stopwords(tokens)  # Remove stopwords\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatize\n",
        "    return tokens\n",
        "\n",
        "# Apply preprocessing\n",
        "df['statement'] = df['statement'].apply(preprocess_text)\n",
        "\n",
        "# Create and train the Word2Vec model\n",
        "model = gensim.models.Word2Vec(\n",
        "    sentences=df['statement'],\n",
        "    vector_size=50,  # Choose an appropriate vector size\n",
        "    window=10,\n",
        "    min_count=2,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Function to get document vectors\n",
        "def document_vector(doc):\n",
        "    doc = [word for word in doc if word in model.wv.index_to_key]\n",
        "    if len(doc) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "    else:\n",
        "        return np.mean(model.wv[doc], axis=0)\n",
        "\n",
        "# Generate document vectors\n",
        "X = []\n",
        "for doc in tqdm(df['statement']):\n",
        "    X.append(document_vector(doc))\n",
        "\n",
        "# Convert X to numpy array and reshape for LSTM\n",
        "X = np.array(X).reshape(len(X), 1, 50)  # Shape it for LSTM (samples, timesteps, features)\n",
        "\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['status'])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Fit SMOTE to the training data\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check the new class distribution\n",
        "print(f\"Original class distribution: {Counter(y_train)}\")\n",
        "print(f\"New class distribution after SMOTE: {Counter(y_train_smote)}\")\n",
        "\n",
        "# Define the model\n",
        "model1 = Sequential()\n",
        "model1.add(LSTM(50, input_shape=(1, 50), return_sequences=False))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(7, activation='softmax'))  # Adjust based on number of classes\n",
        "model1.summary()\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(loss='sparse_categorical_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Define the checkpoint callback\n",
        "checkpoint = ModelCheckpoint(filepath='/content/model1_best.keras',\n",
        "                             monitor='val_accuracy',\n",
        "                             save_best_only=True,\n",
        "                             verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz9u4gKkRkmq"
      },
      "outputs": [],
      "source": [
        "# Train the model with checkpointing\n",
        "model1.fit(X_train_smote,y_train_smote,\n",
        "           validation_data=(X_test, y_test),\n",
        "           epochs=20,\n",
        "           callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOqK0KtHFoeF",
        "outputId": "5252d347-ac93-4591-b930-e2371d46400d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.42.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.112.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.6.2)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.38.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYX-KcfpUrmd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import gradio as gr\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the saved NLP model\n",
        "model = load_model('/content/model1_best.keras')\n",
        "\n",
        "# Initialize or load your tokenizer\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "# Load tokenizer if saved, e.g., tokenizer = load_tokenizer('/path/to/tokenizer.pkl')\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Initialize lemmatizer and stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Manually define the class labels\n",
        "class_labels = ['Anxiety', 'Normal', 'Depression', 'Suicidal', 'Stress', 'Bipolar', 'Personality disorder']\n",
        "encoder = LabelEncoder()\n",
        "encoder.classes_ = np.array(class_labels)\n",
        "\n",
        "# Function to remove extra spaces\n",
        "def remove_extra_spaces(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stopwords]\n",
        "\n",
        "# Preprocessing steps (same as training)\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = remove_extra_spaces(text)  # Remove extra spaces\n",
        "    tokens = word_tokenize(text)  # Tokenize\n",
        "    tokens = remove_stopwords(tokens)  # Remove stopwords\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatize\n",
        "    sequences = tokenizer.texts_to_sequences([' '.join(lemmatized_tokens)])\n",
        "    padded_sequence = pad_sequences(sequences, maxlen=50)  # Adjust maxlen to match the model's input size\n",
        "\n",
        "    # Reshape to (1, 1, 50) as required by the model\n",
        "    padded_sequence = np.reshape(padded_sequence, (1, 1, 50))\n",
        "    return padded_sequence\n",
        "\n",
        "# Prediction function with error handling\n",
        "def predict(text):\n",
        "      # Apply preprocessing\n",
        "      preprocessed_text = preprocess_text(text)\n",
        "\n",
        "      # Make prediction\n",
        "      prediction = model.predict(preprocessed_text)\n",
        "\n",
        "      # Get predicted class index\n",
        "      predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "      # Map index to class label\n",
        "      predicted_class_label = encoder.classes_[predicted_class_index]\n",
        "\n",
        "      return predicted_class_label\n",
        "\n",
        "# Create Gradio interface\n",
        "gr_interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",  # Output will be the predicted class label\n",
        "    title=\"NLP Model Deployment\",\n",
        "    description=\"Enter text for prediction\"\n",
        ")\n",
        "\n",
        "# Launch Gradio app\n",
        "gr_interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "tiQWmO5LXAlK",
        "outputId": "4b6e60d8-4d32-4487-e0f2-dad0d35fa335"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/word2vec_model'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-95e4f8897c49>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Load the Word2Vec model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mword2vec_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/word2vec_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Download required NLTK data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \"\"\"\n\u001b[1;32m   1952\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1954\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \"\"\"\n\u001b[0;32m-> 1459\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/word2vec_model'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from tensorflow.keras.models import load_model\n",
        "import gensim\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the saved NLP model\n",
        "model = load_model('/content/model1_best.keras')\n",
        "\n",
        "# Load the Word2Vec model\n",
        "word2vec_model = gensim.models.Word2Vec.load('/content/word2vec_model')\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Initialize lemmatizer and stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Manually define the class labels\n",
        "class_labels = ['Anxiety', 'Normal', 'Depression', 'Suicidal', 'Stress', 'Bipolar', 'Personality disorder']\n",
        "encoder = LabelEncoder()\n",
        "encoder.classes_ = np.array(class_labels)\n",
        "\n",
        "# Function to remove extra spaces\n",
        "def remove_extra_spaces(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stopwords]\n",
        "\n",
        "# Function to convert text to Word2Vec vectors\n",
        "def text_to_word2vec(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    vectors = [word2vec_model.wv[token] for token in lemmatized_tokens if token in word2vec_model.wv]\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros(word2vec_model.vector_size)\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "# Preprocessing and converting to Word2Vec vectors\n",
        "def preprocess_and_vectorize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = remove_extra_spaces(text)  # Remove extra spaces\n",
        "    vector = text_to_word2vec(text)\n",
        "    return np.reshape(vector, (1, 1, word2vec_model.vector_size))  # Reshape for model input\n",
        "\n",
        "# Prediction function with error handling\n",
        "def predict(text):\n",
        "    try:\n",
        "        # Apply preprocessing and vectorization\n",
        "        preprocessed_vector = preprocess_and_vectorize(text)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = model.predict(preprocessed_vector)\n",
        "\n",
        "        # Get predicted class index\n",
        "        predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "        # Map index to class label\n",
        "        predicted_class_label = encoder.classes_[predicted_class_index]\n",
        "\n",
        "        return predicted_class_label\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Create Gradio interface\n",
        "gr_interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",  # Output will be the predicted class label\n",
        "    title=\"NLP Model Deployment\",\n",
        "    description=\"Enter text for prediction\"\n",
        ")\n",
        "\n",
        "# Launch Gradio app\n",
        "gr_interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "0b-ZTXbjIP5A",
        "outputId": "5ef80b15-7a37-4075-8dc5-212407941be6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Normal</th>\n",
              "      <td>16343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Depression</th>\n",
              "      <td>15404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Suicidal</th>\n",
              "      <td>10652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Anxiety</th>\n",
              "      <td>3841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bipolar</th>\n",
              "      <td>2777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stress</th>\n",
              "      <td>2587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Personality disorder</th>\n",
              "      <td>1077</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "status\n",
              "Normal                  16343\n",
              "Depression              15404\n",
              "Suicidal                10652\n",
              "Anxiety                  3841\n",
              "Bipolar                  2777\n",
              "Stress                   2587\n",
              "Personality disorder     1077\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['status'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "id": "v1ZwQvaKIgnI",
        "outputId": "6cd96317-4c04-4800-cea6-57255e32d925"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "100%|██████████| 52681/52681 [02:44<00:00, 320.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original class distribution: Counter({3: 11356, 2: 10867, 6: 7431, 0: 2707, 1: 1963, 5: 1807, 4: 745})\n",
            "New class distribution after SMOTE: Counter({2: 11356, 3: 11356, 6: 11356, 1: 11356, 0: 11356, 5: 11356, 4: 11356})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">357</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m20,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m357\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,557</span> (80.30 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,557\u001b[0m (80.30 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,557</span> (80.30 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,557\u001b[0m (80.30 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5295 - loss: 1.3302"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"IteratorGetNext:0\", shape=(None, 50), dtype=float32). Expected shape (None, 1, 50), but input has incompatible shape (None, 50)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 50), dtype=float32)\n  • training=False\n  • mask=None",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-d5e69bbc3623>\u001b[0m in \u001b[0;36m<cell line: 165>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;31m# Train the model with checkpointing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m model1.fit(X_train_smote, y_train_smote,\n\u001b[0m\u001b[1;32m    166\u001b[0m            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m_adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m                     \u001b[0madjusted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0;34mf\"Invalid input shape for input {x}. Expected shape \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;34mf\"{ref_shape}, but input has incompatible shape {x.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"IteratorGetNext:0\", shape=(None, 50), dtype=float32). Expected shape (None, 1, 50), but input has incompatible shape (None, 50)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 50), dtype=float32)\n  • training=False\n  • mask=None"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l_D2MNAYBfp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from tensorflow.keras.models import load_model\n",
        "import gensim\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the saved NLP model\n",
        "model = load_model('/content/model1_best.keras')\n",
        "\n",
        "# Load the Word2Vec model\n",
        "word2vec_model = gensim.models.Word2Vec.load('/content/drive/MyDrive/word2vec_model')\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Initialize lemmatizer and stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "#Manually define the class labels\n",
        "class_labels = sort(['Anxiety', 'Normal', 'Depression', 'Suicidal', 'Stress', 'Bipolar', 'Personality disorder'])\n",
        "encoder = LabelEncoder()\n",
        "encoder.classes_ = np.array(class_labels)\n",
        "\n",
        "# Function to remove extra spaces\n",
        "def remove_extra_spaces(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stopwords]\n",
        "\n",
        "# Function to convert text to Word2Vec vectors\n",
        "def text_to_word2vec(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    vectors = [word2vec_model.wv[token] for token in lemmatized_tokens if token in word2vec_model.wv]\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros(word2vec_model.vector_size)\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "# Preprocessing and converting to Word2Vec vectors\n",
        "def preprocess_and_vectorize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = remove_extra_spaces(text)  # Remove extra spaces\n",
        "    vector = text_to_word2vec(text)\n",
        "    return np.reshape(vector, (1, 1, word2vec_model.vector_size))  # Reshape for model input\n",
        "\n",
        "# Prediction function with error handling\n",
        "def predict(text):\n",
        "    try:\n",
        "        # Apply preprocessing and vectorization\n",
        "        preprocessed_vector = preprocess_and_vectorize(text)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = model.predict(preprocessed_vector)\n",
        "\n",
        "        # Get predicted class index\n",
        "        predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "        # Map index to class label\n",
        "        predicted_class_label = encoder.classes_[predicted_class_index]\n",
        "\n",
        "        return predicted_class_label\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Create Gradio interface\n",
        "gr_interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",  # Output will be the predicted class label\n",
        "    title=\"NLP Model Deployment\",\n",
        "    description=\"Enter text for prediction\"\n",
        ")\n",
        "\n",
        "# Launch Gradio app\n",
        "gr_interface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3EUIoTjK8yAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GthUn0ZaYFFO",
        "outputId": "37e9194d-384b-40fa-d829-64781472d13d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "100%|██████████| 52681/52681 [02:03<00:00, 426.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original class distribution: Counter({3: 11356, 2: 10867, 6: 7431, 0: 2707, 1: 1963, 5: 1807, 4: 745})\n",
            "New class distribution after SMOTE: Counter({2: 11356, 3: 11356, 6: 11356, 1: 11356, 0: 11356, 5: 11356, 4: 11356})\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import gensim\n",
        "from nltk import word_tokenize, WordNetLemmatizer, download, corpus\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "# Load and extract ZIP file\n",
        "zip_ref = zipfile.ZipFile('/content/archive (21).zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('/content/Combined Data.csv')\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "df.dropna(inplace=True)\n",
        "df['statement'] = df['statement'].str.lower()\n",
        "\n",
        "# Download NLTK resources\n",
        "download('punkt')\n",
        "download('wordnet')\n",
        "download('stopwords')\n",
        "\n",
        "# Initialize lemmatizer and stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stopwords = set(corpus.stopwords.words('english'))\n",
        "\n",
        "# Function to remove punctuation\n",
        "def remove_punc(text):\n",
        "    return re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "# Function to remove extra spaces\n",
        "def remove_extra_spaces(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stopwords]\n",
        "\n",
        "# Function to handle chatwords\n",
        "def handle_chatwords(text):\n",
        "    replacements = {\n",
        "        \"u\": \"you\",\n",
        "        \"r\": \"are\",\n",
        "        \"ur\": \"your\",\n",
        "        \"cuz\": \"because\",\n",
        "        \"pls\": \"please\",\n",
        "        \"thx\": \"thanks\",\n",
        "        \"LOL\": \"Laugh Out Loud\",\n",
        "        \"BRB\": \"Be Right Back\",\n",
        "        \"OMG\": \"Oh My God\",\n",
        "        \"TTYL\": \"Talk To You Later\",\n",
        "        \"IDK\": \"I Don't Know\",\n",
        "        \"FYI\": \"For Your Information\",\n",
        "        \"BTW\": \"By The Way\",\n",
        "        \"ROFL\": \"Rolling On the Floor Laughing\",\n",
        "        \"SMH\": \"Shaking My Head\",\n",
        "        \"IMO\": \"In My Opinion\",\n",
        "        \"IMHO\": \"In My Humble Opinion\",\n",
        "        \"ICYMI\": \"In Case You Missed It\",\n",
        "        \"DM\": \"Direct Message\",\n",
        "        \"GTG\": \"Got To Go\",\n",
        "        \"G2G\": \"Got To Go\",\n",
        "        \"FTW\": \"For The Win\",\n",
        "        \"AFK\": \"Away From Keyboard\",\n",
        "        \"NP\": \"No Problem\",\n",
        "        \"AMA\": \"Ask Me Anything\",\n",
        "        \"FOMO\": \"Fear Of Missing Out\",\n",
        "        \"OOTD\": \"Outfit Of The Day\",\n",
        "        \"TL;DR\": \"Too Long; Didn't Read\"\n",
        "    }\n",
        "    for chatword, replacement in replacements.items():\n",
        "        text = text.replace(chatword, replacement)\n",
        "    return text\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = remove_punc(text)\n",
        "    text = handle_chatwords(text)\n",
        "    text = remove_extra_spaces(text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return tokens\n",
        "\n",
        "# Apply preprocessing\n",
        "df['statement'] = df['statement'].apply(preprocess_text)\n",
        "\n",
        "# Create and train the Word2Vec model\n",
        "word2vec_model = gensim.models.Word2Vec(\n",
        "    sentences=df['statement'],\n",
        "    vector_size=100,\n",
        "    window=10,\n",
        "    min_count=2,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "\n",
        "# Save the trained Word2Vec model\n",
        "word2vec_model.save('/content/drive/MyDrive/word2vec_model')\n",
        "# Function to get document vectors\n",
        "def document_vector(doc):\n",
        "    doc = [word for word in doc if word in word2vec_model.wv.index_to_key]\n",
        "    if len(doc) == 0:\n",
        "        return np.zeros(word2vec_model.vector_size)\n",
        "    else:\n",
        "        return np.mean(word2vec_model.wv[doc], axis=0)\n",
        "\n",
        "# Generate document vectors\n",
        "X = []\n",
        "for doc in tqdm(df['statement']):\n",
        "    X.append(document_vector(doc))\n",
        "\n",
        "# Convert X to numpy array and flatten for SMOTE\n",
        "X = np.array(X)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['status'])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_flattened, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Fit SMOTE to the flattened training data\n",
        "X_train_smote_flattened, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Reshape the oversampled data back to 3D\n",
        "X_train_smote = X_train_smote_flattened.reshape(X_train_smote_flattened.shape[0], 1, 100)\n",
        "\n",
        "# Check the new class distribution\n",
        "print(f\"Original class distribution: {Counter(y_train)}\")\n",
        "print(f\"New class distribution after SMOTE: {Counter(y_train_smote)}\")\n",
        "\n",
        "# # Define the model\n",
        "# model1 = Sequential()\n",
        "# model1.add(LSTM(50, input_shape=(1, 50), return_sequences=False))\n",
        "# model1.add(Dropout(0.5))\n",
        "# model1.add(Dense(7, activation='softmax'))\n",
        "# model1.summary()\n",
        "\n",
        "# # Compile the model\n",
        "# model1.compile(loss='sparse_categorical_crossentropy',\n",
        "#                optimizer='adam',\n",
        "#                metrics=['accuracy'])\n",
        "\n",
        "# # Define the checkpoint callback\n",
        "# checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/Bestmodel.keras',\n",
        "#                              monitor='val_accuracy',\n",
        "#                              save_best_only=True,\n",
        "#                              verbose=1)\n",
        "# # Train the model with checkpointing\n",
        "# model1.fit(X_train_smote, y_train_smote,\n",
        "#            validation_data=(X_test.reshape(X_test.shape[0], 1, 50), y_test),  # Reshape X_test for LSTM\n",
        "#            epochs=20,\n",
        "#            callbacks=[checkpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "zoYScdTvjp3z",
        "outputId": "39b7d517-1ee7-437e-b479-ac70b5e67cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m30,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m20,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m20,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m357\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">30,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">357</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m70,957\u001b[0m (277.18 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,957</span> (277.18 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,957\u001b[0m (277.18 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,957</span> (277.18 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Initialize the model\n",
        "model1 = Sequential()\n",
        "\n",
        "# Add the first LSTM layer with return_sequences=True to stack more LSTM layers\n",
        "model1.add(LSTM(units=50, return_sequences=True,input_shape=(1, 100)))\n",
        "model1.add(Dropout(0.4))\n",
        "# Add the second LSTM layer\n",
        "model1.add(LSTM(units=50, return_sequences=True))\n",
        "model1.add(Dropout(0.4))\n",
        "\n",
        "model1.add(LSTM(units=50))\n",
        "model1.add(Dropout(0.4))\n",
        "model1.add(Dense(7, activation='softmax'))\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "XxgXDqLpOrDo",
        "outputId": "68be6898-7238-4ea2-b74d-a2d7d8ddbdff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">60,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">30,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">357</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │          \u001b[38;5;34m60,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m30,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m357\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">90,957</span> (355.30 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m90,957\u001b[0m (355.30 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">90,957</span> (355.30 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m90,957\u001b[0m (355.30 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import LSTM, Dropout, Dense, Bidirectional\n",
        "# model1 = Sequential()\n",
        "# # Bidirectional LSTM\n",
        "# model1.add(Bidirectional(LSTM(units=50, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), input_shape=(None, 100)))\n",
        "# model1.add(LSTM(units=50, dropout=0.2, recurrent_dropout=0.2))\n",
        "# model1.add(Dense(7, activation='softmax'))\n",
        "# model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# model1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfV1HOQOdPst"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "# Compile the model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "learning_rate =0.0001\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "model1.compile(loss='sparse_categorical_crossentropy',\n",
        "               optimizer=optimizer,\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Define the checkpoint callback\n",
        "checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/modelnlp2.keras',\n",
        "                             monitor='val_accuracy',\n",
        "                             save_best_only=True,\n",
        "                             verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6WoueaThRLY",
        "outputId": "e2173381-157f-464a-b13f-d4b6d02ec4a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m2475/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3989 - loss: 1.7308\n",
            "Epoch 1: val_accuracy improved from -inf to 0.55350, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.3993 - loss: 1.7298 - val_accuracy: 0.5535 - val_loss: 1.2417\n",
            "Epoch 2/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6000 - loss: 1.1254\n",
            "Epoch 2: val_accuracy improved from 0.55350 to 0.60146, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.6000 - loss: 1.1253 - val_accuracy: 0.6015 - val_loss: 1.1085\n",
            "Epoch 3/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6332 - loss: 1.0282\n",
            "Epoch 3: val_accuracy improved from 0.60146 to 0.62126, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.6332 - loss: 1.0282 - val_accuracy: 0.6213 - val_loss: 1.0385\n",
            "Epoch 4/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6530 - loss: 0.9757\n",
            "Epoch 4: val_accuracy improved from 0.62126 to 0.63891, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.6530 - loss: 0.9757 - val_accuracy: 0.6389 - val_loss: 0.9840\n",
            "Epoch 5/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6615 - loss: 0.9492\n",
            "Epoch 5: val_accuracy improved from 0.63891 to 0.64619, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 10ms/step - accuracy: 0.6616 - loss: 0.9491 - val_accuracy: 0.6462 - val_loss: 0.9557\n",
            "Epoch 6/200\n",
            "\u001b[1m2478/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6707 - loss: 0.9248\n",
            "Epoch 6: val_accuracy did not improve from 0.64619\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.6707 - loss: 0.9248 - val_accuracy: 0.6453 - val_loss: 0.9519\n",
            "Epoch 7/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6753 - loss: 0.9056\n",
            "Epoch 7: val_accuracy improved from 0.64619 to 0.65340, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.6753 - loss: 0.9056 - val_accuracy: 0.6534 - val_loss: 0.9247\n",
            "Epoch 8/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6801 - loss: 0.8978\n",
            "Epoch 8: val_accuracy improved from 0.65340 to 0.65796, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.6801 - loss: 0.8978 - val_accuracy: 0.6580 - val_loss: 0.9105\n",
            "Epoch 9/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6872 - loss: 0.8743\n",
            "Epoch 9: val_accuracy improved from 0.65796 to 0.66194, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.6872 - loss: 0.8743 - val_accuracy: 0.6619 - val_loss: 0.8982\n",
            "Epoch 10/200\n",
            "\u001b[1m2475/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6888 - loss: 0.8723\n",
            "Epoch 10: val_accuracy improved from 0.66194 to 0.66213, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.6888 - loss: 0.8723 - val_accuracy: 0.6621 - val_loss: 0.8853\n",
            "Epoch 11/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6909 - loss: 0.8626\n",
            "Epoch 11: val_accuracy improved from 0.66213 to 0.66593, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.6909 - loss: 0.8626 - val_accuracy: 0.6659 - val_loss: 0.8805\n",
            "Epoch 12/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6960 - loss: 0.8496\n",
            "Epoch 12: val_accuracy did not improve from 0.66593\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.6960 - loss: 0.8496 - val_accuracy: 0.6628 - val_loss: 0.8886\n",
            "Epoch 13/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6975 - loss: 0.8429\n",
            "Epoch 13: val_accuracy improved from 0.66593 to 0.66612, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.6975 - loss: 0.8429 - val_accuracy: 0.6661 - val_loss: 0.8772\n",
            "Epoch 14/200\n",
            "\u001b[1m2478/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7002 - loss: 0.8373\n",
            "Epoch 14: val_accuracy improved from 0.66612 to 0.66852, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7002 - loss: 0.8373 - val_accuracy: 0.6685 - val_loss: 0.8710\n",
            "Epoch 15/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7008 - loss: 0.8267\n",
            "Epoch 15: val_accuracy improved from 0.66852 to 0.67048, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7008 - loss: 0.8267 - val_accuracy: 0.6705 - val_loss: 0.8691\n",
            "Epoch 16/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7045 - loss: 0.8181\n",
            "Epoch 16: val_accuracy improved from 0.67048 to 0.67346, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7045 - loss: 0.8181 - val_accuracy: 0.6735 - val_loss: 0.8572\n",
            "Epoch 17/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7084 - loss: 0.8101\n",
            "Epoch 17: val_accuracy did not improve from 0.67346\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7084 - loss: 0.8101 - val_accuracy: 0.6705 - val_loss: 0.8586\n",
            "Epoch 18/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7108 - loss: 0.8084\n",
            "Epoch 18: val_accuracy improved from 0.67346 to 0.67352, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7108 - loss: 0.8084 - val_accuracy: 0.6735 - val_loss: 0.8545\n",
            "Epoch 19/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7087 - loss: 0.8055\n",
            "Epoch 19: val_accuracy improved from 0.67352 to 0.67358, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7087 - loss: 0.8055 - val_accuracy: 0.6736 - val_loss: 0.8504\n",
            "Epoch 20/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7116 - loss: 0.7968\n",
            "Epoch 20: val_accuracy improved from 0.67358 to 0.67498, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7116 - loss: 0.7968 - val_accuracy: 0.6750 - val_loss: 0.8479\n",
            "Epoch 21/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7134 - loss: 0.7943\n",
            "Epoch 21: val_accuracy improved from 0.67498 to 0.68181, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7134 - loss: 0.7943 - val_accuracy: 0.6818 - val_loss: 0.8290\n",
            "Epoch 22/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7149 - loss: 0.7932\n",
            "Epoch 22: val_accuracy did not improve from 0.68181\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7149 - loss: 0.7932 - val_accuracy: 0.6793 - val_loss: 0.8362\n",
            "Epoch 23/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7157 - loss: 0.7860\n",
            "Epoch 23: val_accuracy improved from 0.68181 to 0.68244, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7157 - loss: 0.7860 - val_accuracy: 0.6824 - val_loss: 0.8299\n",
            "Epoch 24/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7147 - loss: 0.7817\n",
            "Epoch 24: val_accuracy did not improve from 0.68244\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7147 - loss: 0.7817 - val_accuracy: 0.6788 - val_loss: 0.8376\n",
            "Epoch 25/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7160 - loss: 0.7810\n",
            "Epoch 25: val_accuracy did not improve from 0.68244\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7160 - loss: 0.7809 - val_accuracy: 0.6748 - val_loss: 0.8429\n",
            "Epoch 26/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7193 - loss: 0.7792\n",
            "Epoch 26: val_accuracy did not improve from 0.68244\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7193 - loss: 0.7792 - val_accuracy: 0.6803 - val_loss: 0.8274\n",
            "Epoch 27/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7212 - loss: 0.7687\n",
            "Epoch 27: val_accuracy improved from 0.68244 to 0.68396, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7212 - loss: 0.7687 - val_accuracy: 0.6840 - val_loss: 0.8181\n",
            "Epoch 28/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7217 - loss: 0.7678\n",
            "Epoch 28: val_accuracy did not improve from 0.68396\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7217 - loss: 0.7678 - val_accuracy: 0.6833 - val_loss: 0.8246\n",
            "Epoch 29/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7206 - loss: 0.7748\n",
            "Epoch 29: val_accuracy improved from 0.68396 to 0.68497, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7206 - loss: 0.7748 - val_accuracy: 0.6850 - val_loss: 0.8106\n",
            "Epoch 30/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7259 - loss: 0.7644\n",
            "Epoch 30: val_accuracy did not improve from 0.68497\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7259 - loss: 0.7644 - val_accuracy: 0.6780 - val_loss: 0.8373\n",
            "Epoch 31/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7235 - loss: 0.7599\n",
            "Epoch 31: val_accuracy did not improve from 0.68497\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7235 - loss: 0.7599 - val_accuracy: 0.6789 - val_loss: 0.8282\n",
            "Epoch 32/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7230 - loss: 0.7622\n",
            "Epoch 32: val_accuracy did not improve from 0.68497\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7230 - loss: 0.7622 - val_accuracy: 0.6806 - val_loss: 0.8208\n",
            "Epoch 33/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7232 - loss: 0.7580\n",
            "Epoch 33: val_accuracy did not improve from 0.68497\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7232 - loss: 0.7579 - val_accuracy: 0.6847 - val_loss: 0.8135\n",
            "Epoch 34/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7228 - loss: 0.7550\n",
            "Epoch 34: val_accuracy did not improve from 0.68497\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7228 - loss: 0.7550 - val_accuracy: 0.6797 - val_loss: 0.8326\n",
            "Epoch 35/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7284 - loss: 0.7529\n",
            "Epoch 35: val_accuracy did not improve from 0.68497\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.7284 - loss: 0.7529 - val_accuracy: 0.6808 - val_loss: 0.8217\n",
            "Epoch 36/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7270 - loss: 0.7476\n",
            "Epoch 36: val_accuracy did not improve from 0.68497\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - accuracy: 0.7270 - loss: 0.7476 - val_accuracy: 0.6776 - val_loss: 0.8279\n",
            "Epoch 37/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7273 - loss: 0.7420\n",
            "Epoch 37: val_accuracy did not improve from 0.68497\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - accuracy: 0.7273 - loss: 0.7420 - val_accuracy: 0.6790 - val_loss: 0.8363\n",
            "Epoch 38/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7292 - loss: 0.7470\n",
            "Epoch 38: val_accuracy did not improve from 0.68497\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.7292 - loss: 0.7470 - val_accuracy: 0.6850 - val_loss: 0.8248\n",
            "Epoch 39/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7314 - loss: 0.7352\n",
            "Epoch 39: val_accuracy did not improve from 0.68497\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7314 - loss: 0.7352 - val_accuracy: 0.6838 - val_loss: 0.8139\n",
            "Epoch 40/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7353 - loss: 0.7317\n",
            "Epoch 40: val_accuracy improved from 0.68497 to 0.68858, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7353 - loss: 0.7317 - val_accuracy: 0.6886 - val_loss: 0.8033\n",
            "Epoch 41/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7318 - loss: 0.7369\n",
            "Epoch 41: val_accuracy did not improve from 0.68858\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7318 - loss: 0.7369 - val_accuracy: 0.6846 - val_loss: 0.8188\n",
            "Epoch 42/200\n",
            "\u001b[1m2475/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7317 - loss: 0.7341\n",
            "Epoch 42: val_accuracy did not improve from 0.68858\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7317 - loss: 0.7341 - val_accuracy: 0.6845 - val_loss: 0.8122\n",
            "Epoch 43/200\n",
            "\u001b[1m2475/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7340 - loss: 0.7331\n",
            "Epoch 43: val_accuracy did not improve from 0.68858\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7340 - loss: 0.7331 - val_accuracy: 0.6866 - val_loss: 0.8089\n",
            "Epoch 44/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7362 - loss: 0.7283\n",
            "Epoch 44: val_accuracy did not improve from 0.68858\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7362 - loss: 0.7283 - val_accuracy: 0.6832 - val_loss: 0.8170\n",
            "Epoch 45/200\n",
            "\u001b[1m2475/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7341 - loss: 0.7287\n",
            "Epoch 45: val_accuracy improved from 0.68858 to 0.68915, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7341 - loss: 0.7287 - val_accuracy: 0.6891 - val_loss: 0.7989\n",
            "Epoch 46/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7379 - loss: 0.7237\n",
            "Epoch 46: val_accuracy did not improve from 0.68915\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7379 - loss: 0.7237 - val_accuracy: 0.6824 - val_loss: 0.8208\n",
            "Epoch 47/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7372 - loss: 0.7236\n",
            "Epoch 47: val_accuracy improved from 0.68915 to 0.68984, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7372 - loss: 0.7236 - val_accuracy: 0.6898 - val_loss: 0.8015\n",
            "Epoch 48/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7391 - loss: 0.7171\n",
            "Epoch 48: val_accuracy improved from 0.68984 to 0.69212, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7391 - loss: 0.7171 - val_accuracy: 0.6921 - val_loss: 0.8031\n",
            "Epoch 49/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7360 - loss: 0.7202\n",
            "Epoch 49: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7360 - loss: 0.7202 - val_accuracy: 0.6837 - val_loss: 0.8206\n",
            "Epoch 50/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7409 - loss: 0.7121\n",
            "Epoch 50: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7409 - loss: 0.7121 - val_accuracy: 0.6866 - val_loss: 0.8093\n",
            "Epoch 51/200\n",
            "\u001b[1m2475/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7373 - loss: 0.7159\n",
            "Epoch 51: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7373 - loss: 0.7159 - val_accuracy: 0.6859 - val_loss: 0.8128\n",
            "Epoch 52/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7367 - loss: 0.7143\n",
            "Epoch 52: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7367 - loss: 0.7143 - val_accuracy: 0.6890 - val_loss: 0.8076\n",
            "Epoch 53/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7407 - loss: 0.7099\n",
            "Epoch 53: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7407 - loss: 0.7099 - val_accuracy: 0.6849 - val_loss: 0.8170\n",
            "Epoch 54/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7413 - loss: 0.7034\n",
            "Epoch 54: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7413 - loss: 0.7034 - val_accuracy: 0.6894 - val_loss: 0.8075\n",
            "Epoch 55/200\n",
            "\u001b[1m2478/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7378 - loss: 0.7099\n",
            "Epoch 55: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7378 - loss: 0.7099 - val_accuracy: 0.6855 - val_loss: 0.8141\n",
            "Epoch 56/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7419 - loss: 0.7025\n",
            "Epoch 56: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7419 - loss: 0.7025 - val_accuracy: 0.6894 - val_loss: 0.8067\n",
            "Epoch 57/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7432 - loss: 0.7067\n",
            "Epoch 57: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7432 - loss: 0.7067 - val_accuracy: 0.6905 - val_loss: 0.8035\n",
            "Epoch 58/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7415 - loss: 0.7074\n",
            "Epoch 58: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7415 - loss: 0.7074 - val_accuracy: 0.6902 - val_loss: 0.7962\n",
            "Epoch 59/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7439 - loss: 0.7011\n",
            "Epoch 59: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7439 - loss: 0.7011 - val_accuracy: 0.6819 - val_loss: 0.8317\n",
            "Epoch 60/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7460 - loss: 0.6931\n",
            "Epoch 60: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7460 - loss: 0.6932 - val_accuracy: 0.6876 - val_loss: 0.8098\n",
            "Epoch 61/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7393 - loss: 0.7036\n",
            "Epoch 61: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7393 - loss: 0.7035 - val_accuracy: 0.6831 - val_loss: 0.8264\n",
            "Epoch 62/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7392 - loss: 0.7039\n",
            "Epoch 62: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7392 - loss: 0.7039 - val_accuracy: 0.6895 - val_loss: 0.8029\n",
            "Epoch 63/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7465 - loss: 0.6947\n",
            "Epoch 63: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7464 - loss: 0.6947 - val_accuracy: 0.6858 - val_loss: 0.8201\n",
            "Epoch 64/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7461 - loss: 0.6952\n",
            "Epoch 64: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7461 - loss: 0.6952 - val_accuracy: 0.6915 - val_loss: 0.8003\n",
            "Epoch 65/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7470 - loss: 0.6911\n",
            "Epoch 65: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7470 - loss: 0.6911 - val_accuracy: 0.6874 - val_loss: 0.8099\n",
            "Epoch 66/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7462 - loss: 0.6935\n",
            "Epoch 66: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7462 - loss: 0.6935 - val_accuracy: 0.6843 - val_loss: 0.8268\n",
            "Epoch 67/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7449 - loss: 0.6948\n",
            "Epoch 67: val_accuracy did not improve from 0.69212\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7449 - loss: 0.6948 - val_accuracy: 0.6916 - val_loss: 0.8013\n",
            "Epoch 68/200\n",
            "\u001b[1m2478/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7488 - loss: 0.6845\n",
            "Epoch 68: val_accuracy improved from 0.69212 to 0.69434, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7488 - loss: 0.6845 - val_accuracy: 0.6943 - val_loss: 0.7908\n",
            "Epoch 69/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7478 - loss: 0.6874\n",
            "Epoch 69: val_accuracy did not improve from 0.69434\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7478 - loss: 0.6874 - val_accuracy: 0.6886 - val_loss: 0.8152\n",
            "Epoch 70/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7449 - loss: 0.6940\n",
            "Epoch 70: val_accuracy did not improve from 0.69434\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7449 - loss: 0.6940 - val_accuracy: 0.6874 - val_loss: 0.8127\n",
            "Epoch 71/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7457 - loss: 0.6882\n",
            "Epoch 71: val_accuracy did not improve from 0.69434\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7457 - loss: 0.6882 - val_accuracy: 0.6904 - val_loss: 0.8015\n",
            "Epoch 72/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7480 - loss: 0.6871\n",
            "Epoch 72: val_accuracy did not improve from 0.69434\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7480 - loss: 0.6871 - val_accuracy: 0.6855 - val_loss: 0.8171\n",
            "Epoch 73/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7477 - loss: 0.6815\n",
            "Epoch 73: val_accuracy did not improve from 0.69434\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7477 - loss: 0.6815 - val_accuracy: 0.6901 - val_loss: 0.8090\n",
            "Epoch 74/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7501 - loss: 0.6795\n",
            "Epoch 74: val_accuracy did not improve from 0.69434\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7501 - loss: 0.6795 - val_accuracy: 0.6891 - val_loss: 0.8111\n",
            "Epoch 75/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7491 - loss: 0.6855\n",
            "Epoch 75: val_accuracy did not improve from 0.69434\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7491 - loss: 0.6855 - val_accuracy: 0.6898 - val_loss: 0.8108\n",
            "Epoch 76/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7521 - loss: 0.6798\n",
            "Epoch 76: val_accuracy did not improve from 0.69434\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7521 - loss: 0.6798 - val_accuracy: 0.6885 - val_loss: 0.8174\n",
            "Epoch 77/200\n",
            "\u001b[1m2478/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7524 - loss: 0.6752\n",
            "Epoch 77: val_accuracy did not improve from 0.69434\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7524 - loss: 0.6752 - val_accuracy: 0.6857 - val_loss: 0.8242\n",
            "Epoch 78/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7501 - loss: 0.6809\n",
            "Epoch 78: val_accuracy did not improve from 0.69434\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7501 - loss: 0.6809 - val_accuracy: 0.6908 - val_loss: 0.8017\n",
            "Epoch 79/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7492 - loss: 0.6766\n",
            "Epoch 79: val_accuracy did not improve from 0.69434\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.7492 - loss: 0.6766 - val_accuracy: 0.6893 - val_loss: 0.8117\n",
            "Epoch 80/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7516 - loss: 0.6784\n",
            "Epoch 80: val_accuracy improved from 0.69434 to 0.69946, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7516 - loss: 0.6783 - val_accuracy: 0.6995 - val_loss: 0.7917\n",
            "Epoch 81/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7498 - loss: 0.6775\n",
            "Epoch 81: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7498 - loss: 0.6775 - val_accuracy: 0.6911 - val_loss: 0.8115\n",
            "Epoch 82/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7521 - loss: 0.6724\n",
            "Epoch 82: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7521 - loss: 0.6724 - val_accuracy: 0.6966 - val_loss: 0.7957\n",
            "Epoch 83/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7530 - loss: 0.6707\n",
            "Epoch 83: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.7530 - loss: 0.6707 - val_accuracy: 0.6929 - val_loss: 0.8048\n",
            "Epoch 84/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7539 - loss: 0.6722\n",
            "Epoch 84: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.7539 - loss: 0.6722 - val_accuracy: 0.6843 - val_loss: 0.8315\n",
            "Epoch 85/200\n",
            "\u001b[1m2475/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7553 - loss: 0.6678\n",
            "Epoch 85: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.7553 - loss: 0.6678 - val_accuracy: 0.6948 - val_loss: 0.7982\n",
            "Epoch 86/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7542 - loss: 0.6697\n",
            "Epoch 86: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.7542 - loss: 0.6697 - val_accuracy: 0.6942 - val_loss: 0.8076\n",
            "Epoch 87/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7515 - loss: 0.6694\n",
            "Epoch 87: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.7516 - loss: 0.6694 - val_accuracy: 0.6953 - val_loss: 0.8004\n",
            "Epoch 88/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7528 - loss: 0.6720\n",
            "Epoch 88: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7528 - loss: 0.6719 - val_accuracy: 0.6955 - val_loss: 0.7969\n",
            "Epoch 89/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7564 - loss: 0.6661\n",
            "Epoch 89: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.7564 - loss: 0.6661 - val_accuracy: 0.6922 - val_loss: 0.7986\n",
            "Epoch 90/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7574 - loss: 0.6621\n",
            "Epoch 90: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7573 - loss: 0.6621 - val_accuracy: 0.6957 - val_loss: 0.7882\n",
            "Epoch 91/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7574 - loss: 0.6636\n",
            "Epoch 91: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.7574 - loss: 0.6636 - val_accuracy: 0.6925 - val_loss: 0.8007\n",
            "Epoch 92/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7585 - loss: 0.6579\n",
            "Epoch 92: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7585 - loss: 0.6579 - val_accuracy: 0.6931 - val_loss: 0.8054\n",
            "Epoch 93/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7569 - loss: 0.6602\n",
            "Epoch 93: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7569 - loss: 0.6602 - val_accuracy: 0.6917 - val_loss: 0.8069\n",
            "Epoch 94/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7556 - loss: 0.6637\n",
            "Epoch 94: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7556 - loss: 0.6637 - val_accuracy: 0.6943 - val_loss: 0.7988\n",
            "Epoch 95/200\n",
            "\u001b[1m2475/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7583 - loss: 0.6537\n",
            "Epoch 95: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7583 - loss: 0.6537 - val_accuracy: 0.6972 - val_loss: 0.7993\n",
            "Epoch 96/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7588 - loss: 0.6580\n",
            "Epoch 96: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7588 - loss: 0.6580 - val_accuracy: 0.6885 - val_loss: 0.8092\n",
            "Epoch 97/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7584 - loss: 0.6585\n",
            "Epoch 97: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7584 - loss: 0.6585 - val_accuracy: 0.6945 - val_loss: 0.8038\n",
            "Epoch 98/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7593 - loss: 0.6558\n",
            "Epoch 98: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7592 - loss: 0.6558 - val_accuracy: 0.6922 - val_loss: 0.8058\n",
            "Epoch 99/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7573 - loss: 0.6604\n",
            "Epoch 99: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.7573 - loss: 0.6604 - val_accuracy: 0.6965 - val_loss: 0.7957\n",
            "Epoch 100/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7597 - loss: 0.6564\n",
            "Epoch 100: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7597 - loss: 0.6564 - val_accuracy: 0.6889 - val_loss: 0.8163\n",
            "Epoch 101/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7593 - loss: 0.6555\n",
            "Epoch 101: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7593 - loss: 0.6555 - val_accuracy: 0.6969 - val_loss: 0.7956\n",
            "Epoch 102/200\n",
            "\u001b[1m2478/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7583 - loss: 0.6535\n",
            "Epoch 102: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7583 - loss: 0.6535 - val_accuracy: 0.6953 - val_loss: 0.8045\n",
            "Epoch 103/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7618 - loss: 0.6499\n",
            "Epoch 103: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7618 - loss: 0.6499 - val_accuracy: 0.6979 - val_loss: 0.7916\n",
            "Epoch 104/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7583 - loss: 0.6536\n",
            "Epoch 104: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7583 - loss: 0.6536 - val_accuracy: 0.6893 - val_loss: 0.8183\n",
            "Epoch 105/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7617 - loss: 0.6454\n",
            "Epoch 105: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7617 - loss: 0.6454 - val_accuracy: 0.6902 - val_loss: 0.8091\n",
            "Epoch 106/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7584 - loss: 0.6537\n",
            "Epoch 106: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.7584 - loss: 0.6537 - val_accuracy: 0.6990 - val_loss: 0.7957\n",
            "Epoch 107/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7625 - loss: 0.6462\n",
            "Epoch 107: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7625 - loss: 0.6462 - val_accuracy: 0.6932 - val_loss: 0.8000\n",
            "Epoch 108/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7601 - loss: 0.6524\n",
            "Epoch 108: val_accuracy did not improve from 0.69946\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7601 - loss: 0.6524 - val_accuracy: 0.6938 - val_loss: 0.8071\n",
            "Epoch 109/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6474\n",
            "Epoch 109: val_accuracy improved from 0.69946 to 0.70047, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.6474 - val_accuracy: 0.7005 - val_loss: 0.7920\n",
            "Epoch 110/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7613 - loss: 0.6517\n",
            "Epoch 110: val_accuracy did not improve from 0.70047\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7613 - loss: 0.6517 - val_accuracy: 0.6941 - val_loss: 0.8012\n",
            "Epoch 111/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7571 - loss: 0.6520\n",
            "Epoch 111: val_accuracy did not improve from 0.70047\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7571 - loss: 0.6520 - val_accuracy: 0.6951 - val_loss: 0.7995\n",
            "Epoch 112/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7594 - loss: 0.6501\n",
            "Epoch 112: val_accuracy did not improve from 0.70047\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7594 - loss: 0.6501 - val_accuracy: 0.6903 - val_loss: 0.8156\n",
            "Epoch 113/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6423\n",
            "Epoch 113: val_accuracy did not improve from 0.70047\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.6423 - val_accuracy: 0.6948 - val_loss: 0.8038\n",
            "Epoch 114/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7626 - loss: 0.6457\n",
            "Epoch 114: val_accuracy did not improve from 0.70047\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7626 - loss: 0.6457 - val_accuracy: 0.6963 - val_loss: 0.7989\n",
            "Epoch 115/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7660 - loss: 0.6376\n",
            "Epoch 115: val_accuracy did not improve from 0.70047\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7660 - loss: 0.6376 - val_accuracy: 0.6979 - val_loss: 0.8013\n",
            "Epoch 116/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7627 - loss: 0.6419\n",
            "Epoch 116: val_accuracy did not improve from 0.70047\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7627 - loss: 0.6419 - val_accuracy: 0.6945 - val_loss: 0.8049\n",
            "Epoch 117/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7597 - loss: 0.6455\n",
            "Epoch 117: val_accuracy did not improve from 0.70047\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7598 - loss: 0.6455 - val_accuracy: 0.6941 - val_loss: 0.8041\n",
            "Epoch 118/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7643 - loss: 0.6410\n",
            "Epoch 118: val_accuracy did not improve from 0.70047\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7643 - loss: 0.6410 - val_accuracy: 0.6966 - val_loss: 0.8012\n",
            "Epoch 119/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7620 - loss: 0.6441\n",
            "Epoch 119: val_accuracy did not improve from 0.70047\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7621 - loss: 0.6441 - val_accuracy: 0.6946 - val_loss: 0.8040\n",
            "Epoch 120/200\n",
            "\u001b[1m2475/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7603 - loss: 0.6471\n",
            "Epoch 120: val_accuracy did not improve from 0.70047\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7603 - loss: 0.6471 - val_accuracy: 0.6996 - val_loss: 0.7968\n",
            "Epoch 121/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7635 - loss: 0.6395\n",
            "Epoch 121: val_accuracy did not improve from 0.70047\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7635 - loss: 0.6395 - val_accuracy: 0.6986 - val_loss: 0.7946\n",
            "Epoch 122/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7658 - loss: 0.6353\n",
            "Epoch 122: val_accuracy improved from 0.70047 to 0.70079, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7658 - loss: 0.6353 - val_accuracy: 0.7008 - val_loss: 0.7918\n",
            "Epoch 123/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7631 - loss: 0.6412\n",
            "Epoch 123: val_accuracy did not improve from 0.70079\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7631 - loss: 0.6412 - val_accuracy: 0.6976 - val_loss: 0.8029\n",
            "Epoch 124/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7679 - loss: 0.6337\n",
            "Epoch 124: val_accuracy did not improve from 0.70079\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7679 - loss: 0.6338 - val_accuracy: 0.6997 - val_loss: 0.7929\n",
            "Epoch 125/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7642 - loss: 0.6341\n",
            "Epoch 125: val_accuracy did not improve from 0.70079\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7642 - loss: 0.6341 - val_accuracy: 0.6956 - val_loss: 0.7995\n",
            "Epoch 126/200\n",
            "\u001b[1m2478/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7598 - loss: 0.6387\n",
            "Epoch 126: val_accuracy did not improve from 0.70079\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7598 - loss: 0.6387 - val_accuracy: 0.6924 - val_loss: 0.8146\n",
            "Epoch 127/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7632 - loss: 0.6377\n",
            "Epoch 127: val_accuracy did not improve from 0.70079\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7632 - loss: 0.6377 - val_accuracy: 0.6979 - val_loss: 0.7998\n",
            "Epoch 128/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7681 - loss: 0.6326\n",
            "Epoch 128: val_accuracy did not improve from 0.70079\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7681 - loss: 0.6326 - val_accuracy: 0.6936 - val_loss: 0.8089\n",
            "Epoch 129/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7644 - loss: 0.6352\n",
            "Epoch 129: val_accuracy improved from 0.70079 to 0.70092, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.7644 - loss: 0.6352 - val_accuracy: 0.7009 - val_loss: 0.7972\n",
            "Epoch 130/200\n",
            "\u001b[1m2478/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7660 - loss: 0.6318\n",
            "Epoch 130: val_accuracy improved from 0.70092 to 0.70256, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7660 - loss: 0.6318 - val_accuracy: 0.7026 - val_loss: 0.7856\n",
            "Epoch 131/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7655 - loss: 0.6345\n",
            "Epoch 131: val_accuracy did not improve from 0.70256\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7655 - loss: 0.6345 - val_accuracy: 0.6869 - val_loss: 0.8352\n",
            "Epoch 132/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7666 - loss: 0.6326\n",
            "Epoch 132: val_accuracy did not improve from 0.70256\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7666 - loss: 0.6326 - val_accuracy: 0.6965 - val_loss: 0.8027\n",
            "Epoch 133/200\n",
            "\u001b[1m2478/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7648 - loss: 0.6331\n",
            "Epoch 133: val_accuracy did not improve from 0.70256\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7648 - loss: 0.6331 - val_accuracy: 0.6963 - val_loss: 0.8082\n",
            "Epoch 134/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7685 - loss: 0.6256\n",
            "Epoch 134: val_accuracy did not improve from 0.70256\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7685 - loss: 0.6256 - val_accuracy: 0.6997 - val_loss: 0.7983\n",
            "Epoch 135/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7698 - loss: 0.6279\n",
            "Epoch 135: val_accuracy did not improve from 0.70256\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7698 - loss: 0.6279 - val_accuracy: 0.6927 - val_loss: 0.8162\n",
            "Epoch 136/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7679 - loss: 0.6272\n",
            "Epoch 136: val_accuracy did not improve from 0.70256\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7679 - loss: 0.6272 - val_accuracy: 0.6939 - val_loss: 0.8100\n",
            "Epoch 137/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7645 - loss: 0.6352\n",
            "Epoch 137: val_accuracy did not improve from 0.70256\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7645 - loss: 0.6352 - val_accuracy: 0.6880 - val_loss: 0.8270\n",
            "Epoch 138/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7699 - loss: 0.6275\n",
            "Epoch 138: val_accuracy did not improve from 0.70256\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.7699 - loss: 0.6275 - val_accuracy: 0.6960 - val_loss: 0.8084\n",
            "Epoch 139/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7677 - loss: 0.6263\n",
            "Epoch 139: val_accuracy improved from 0.70256 to 0.70452, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7677 - loss: 0.6263 - val_accuracy: 0.7045 - val_loss: 0.7839\n",
            "Epoch 140/200\n",
            "\u001b[1m2478/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7684 - loss: 0.6291\n",
            "Epoch 140: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7684 - loss: 0.6291 - val_accuracy: 0.6987 - val_loss: 0.7914\n",
            "Epoch 141/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7672 - loss: 0.6290\n",
            "Epoch 141: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7672 - loss: 0.6290 - val_accuracy: 0.6914 - val_loss: 0.8172\n",
            "Epoch 142/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7658 - loss: 0.6289\n",
            "Epoch 142: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7658 - loss: 0.6289 - val_accuracy: 0.7014 - val_loss: 0.7905\n",
            "Epoch 143/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7659 - loss: 0.6283\n",
            "Epoch 143: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.7659 - loss: 0.6283 - val_accuracy: 0.7000 - val_loss: 0.7922\n",
            "Epoch 144/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7660 - loss: 0.6288\n",
            "Epoch 144: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7660 - loss: 0.6288 - val_accuracy: 0.6964 - val_loss: 0.8049\n",
            "Epoch 145/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7697 - loss: 0.6225\n",
            "Epoch 145: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7697 - loss: 0.6225 - val_accuracy: 0.6947 - val_loss: 0.8037\n",
            "Epoch 146/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7733 - loss: 0.6203\n",
            "Epoch 146: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7733 - loss: 0.6204 - val_accuracy: 0.6954 - val_loss: 0.8049\n",
            "Epoch 147/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7721 - loss: 0.6145\n",
            "Epoch 147: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7721 - loss: 0.6145 - val_accuracy: 0.7017 - val_loss: 0.7928\n",
            "Epoch 148/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7701 - loss: 0.6207\n",
            "Epoch 148: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7701 - loss: 0.6207 - val_accuracy: 0.6969 - val_loss: 0.8095\n",
            "Epoch 149/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7670 - loss: 0.6281\n",
            "Epoch 149: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7670 - loss: 0.6281 - val_accuracy: 0.6904 - val_loss: 0.8205\n",
            "Epoch 150/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7716 - loss: 0.6178\n",
            "Epoch 150: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7716 - loss: 0.6178 - val_accuracy: 0.6991 - val_loss: 0.7894\n",
            "Epoch 151/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7703 - loss: 0.6189\n",
            "Epoch 151: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7703 - loss: 0.6189 - val_accuracy: 0.6945 - val_loss: 0.8049\n",
            "Epoch 152/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7698 - loss: 0.6231\n",
            "Epoch 152: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7698 - loss: 0.6231 - val_accuracy: 0.6935 - val_loss: 0.8108\n",
            "Epoch 153/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7699 - loss: 0.6188\n",
            "Epoch 153: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7699 - loss: 0.6187 - val_accuracy: 0.6938 - val_loss: 0.8111\n",
            "Epoch 154/200\n",
            "\u001b[1m2478/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7718 - loss: 0.6162\n",
            "Epoch 154: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7718 - loss: 0.6162 - val_accuracy: 0.6990 - val_loss: 0.8086\n",
            "Epoch 155/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7724 - loss: 0.6170\n",
            "Epoch 155: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7724 - loss: 0.6170 - val_accuracy: 0.6935 - val_loss: 0.8151\n",
            "Epoch 156/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7683 - loss: 0.6208\n",
            "Epoch 156: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7683 - loss: 0.6208 - val_accuracy: 0.6951 - val_loss: 0.8173\n",
            "Epoch 157/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7721 - loss: 0.6166\n",
            "Epoch 157: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7721 - loss: 0.6166 - val_accuracy: 0.6975 - val_loss: 0.7966\n",
            "Epoch 158/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7729 - loss: 0.6169\n",
            "Epoch 158: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7729 - loss: 0.6169 - val_accuracy: 0.6957 - val_loss: 0.8036\n",
            "Epoch 159/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7704 - loss: 0.6205\n",
            "Epoch 159: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7704 - loss: 0.6205 - val_accuracy: 0.6918 - val_loss: 0.8164\n",
            "Epoch 160/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7737 - loss: 0.6132\n",
            "Epoch 160: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7737 - loss: 0.6132 - val_accuracy: 0.7002 - val_loss: 0.7954\n",
            "Epoch 161/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7735 - loss: 0.6158\n",
            "Epoch 161: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7735 - loss: 0.6158 - val_accuracy: 0.6997 - val_loss: 0.8039\n",
            "Epoch 162/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7743 - loss: 0.6105\n",
            "Epoch 162: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7743 - loss: 0.6105 - val_accuracy: 0.7025 - val_loss: 0.7902\n",
            "Epoch 163/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7753 - loss: 0.6126\n",
            "Epoch 163: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7753 - loss: 0.6126 - val_accuracy: 0.7043 - val_loss: 0.7848\n",
            "Epoch 164/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7726 - loss: 0.6138\n",
            "Epoch 164: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7726 - loss: 0.6138 - val_accuracy: 0.6953 - val_loss: 0.8100\n",
            "Epoch 165/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7724 - loss: 0.6095\n",
            "Epoch 165: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7724 - loss: 0.6095 - val_accuracy: 0.6969 - val_loss: 0.8088\n",
            "Epoch 166/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7744 - loss: 0.6094\n",
            "Epoch 166: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7744 - loss: 0.6094 - val_accuracy: 0.6977 - val_loss: 0.8015\n",
            "Epoch 167/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7715 - loss: 0.6083\n",
            "Epoch 167: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7715 - loss: 0.6083 - val_accuracy: 0.7009 - val_loss: 0.8050\n",
            "Epoch 168/200\n",
            "\u001b[1m2478/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7722 - loss: 0.6124\n",
            "Epoch 168: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7722 - loss: 0.6124 - val_accuracy: 0.6990 - val_loss: 0.8095\n",
            "Epoch 169/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7735 - loss: 0.6080\n",
            "Epoch 169: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7735 - loss: 0.6081 - val_accuracy: 0.6949 - val_loss: 0.8164\n",
            "Epoch 170/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7729 - loss: 0.6078\n",
            "Epoch 170: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7729 - loss: 0.6078 - val_accuracy: 0.7028 - val_loss: 0.7881\n",
            "Epoch 171/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7747 - loss: 0.6097\n",
            "Epoch 171: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7747 - loss: 0.6097 - val_accuracy: 0.6971 - val_loss: 0.8088\n",
            "Epoch 172/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7775 - loss: 0.6056\n",
            "Epoch 172: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7775 - loss: 0.6056 - val_accuracy: 0.6977 - val_loss: 0.8055\n",
            "Epoch 173/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7709 - loss: 0.6115\n",
            "Epoch 173: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7709 - loss: 0.6115 - val_accuracy: 0.7004 - val_loss: 0.7958\n",
            "Epoch 174/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7720 - loss: 0.6140\n",
            "Epoch 174: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7720 - loss: 0.6140 - val_accuracy: 0.6967 - val_loss: 0.8038\n",
            "Epoch 175/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7733 - loss: 0.6118\n",
            "Epoch 175: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7733 - loss: 0.6118 - val_accuracy: 0.7003 - val_loss: 0.8021\n",
            "Epoch 176/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7740 - loss: 0.6123\n",
            "Epoch 176: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7740 - loss: 0.6122 - val_accuracy: 0.7036 - val_loss: 0.7907\n",
            "Epoch 177/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7765 - loss: 0.6053\n",
            "Epoch 177: val_accuracy did not improve from 0.70452\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7765 - loss: 0.6053 - val_accuracy: 0.6941 - val_loss: 0.8107\n",
            "Epoch 178/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7783 - loss: 0.6029\n",
            "Epoch 178: val_accuracy improved from 0.70452 to 0.70465, saving model to /content/drive/MyDrive/modelnlp2.keras\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7783 - loss: 0.6029 - val_accuracy: 0.7047 - val_loss: 0.7838\n",
            "Epoch 179/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7758 - loss: 0.6042\n",
            "Epoch 179: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7758 - loss: 0.6042 - val_accuracy: 0.6994 - val_loss: 0.8015\n",
            "Epoch 180/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7753 - loss: 0.6090\n",
            "Epoch 180: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7753 - loss: 0.6090 - val_accuracy: 0.6971 - val_loss: 0.8123\n",
            "Epoch 181/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7740 - loss: 0.6108\n",
            "Epoch 181: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7740 - loss: 0.6108 - val_accuracy: 0.6981 - val_loss: 0.8097\n",
            "Epoch 182/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7761 - loss: 0.6034\n",
            "Epoch 182: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7761 - loss: 0.6034 - val_accuracy: 0.6936 - val_loss: 0.8202\n",
            "Epoch 183/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7702 - loss: 0.6105\n",
            "Epoch 183: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7703 - loss: 0.6105 - val_accuracy: 0.7010 - val_loss: 0.7993\n",
            "Epoch 184/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7767 - loss: 0.6014\n",
            "Epoch 184: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7767 - loss: 0.6014 - val_accuracy: 0.6980 - val_loss: 0.8073\n",
            "Epoch 185/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7728 - loss: 0.6081\n",
            "Epoch 185: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7728 - loss: 0.6080 - val_accuracy: 0.7019 - val_loss: 0.7961\n",
            "Epoch 186/200\n",
            "\u001b[1m2484/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7754 - loss: 0.6042\n",
            "Epoch 186: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7754 - loss: 0.6042 - val_accuracy: 0.6999 - val_loss: 0.7982\n",
            "Epoch 187/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7749 - loss: 0.6037\n",
            "Epoch 187: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7749 - loss: 0.6037 - val_accuracy: 0.6988 - val_loss: 0.8068\n",
            "Epoch 188/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7760 - loss: 0.5961\n",
            "Epoch 188: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7760 - loss: 0.5961 - val_accuracy: 0.6989 - val_loss: 0.7966\n",
            "Epoch 189/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7738 - loss: 0.6059\n",
            "Epoch 189: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7738 - loss: 0.6059 - val_accuracy: 0.6941 - val_loss: 0.8152\n",
            "Epoch 190/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7729 - loss: 0.6047\n",
            "Epoch 190: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.7729 - loss: 0.6047 - val_accuracy: 0.6947 - val_loss: 0.8091\n",
            "Epoch 191/200\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7775 - loss: 0.5995\n",
            "Epoch 191: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7775 - loss: 0.5995 - val_accuracy: 0.6976 - val_loss: 0.8046\n",
            "Epoch 192/200\n",
            "\u001b[1m2483/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7797 - loss: 0.5958\n",
            "Epoch 192: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.7797 - loss: 0.5958 - val_accuracy: 0.6956 - val_loss: 0.8169\n",
            "Epoch 193/200\n",
            "\u001b[1m2476/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7761 - loss: 0.5992\n",
            "Epoch 193: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7761 - loss: 0.5992 - val_accuracy: 0.6979 - val_loss: 0.8012\n",
            "Epoch 194/200\n",
            "\u001b[1m2479/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7791 - loss: 0.5958\n",
            "Epoch 194: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7791 - loss: 0.5958 - val_accuracy: 0.6954 - val_loss: 0.8137\n",
            "Epoch 195/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7797 - loss: 0.5948\n",
            "Epoch 195: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7797 - loss: 0.5948 - val_accuracy: 0.6950 - val_loss: 0.8083\n",
            "Epoch 196/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7792 - loss: 0.5946\n",
            "Epoch 196: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.7792 - loss: 0.5946 - val_accuracy: 0.7014 - val_loss: 0.7930\n",
            "Epoch 197/200\n",
            "\u001b[1m2477/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7812 - loss: 0.5888\n",
            "Epoch 197: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7812 - loss: 0.5888 - val_accuracy: 0.6951 - val_loss: 0.8138\n",
            "Epoch 198/200\n",
            "\u001b[1m2482/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7796 - loss: 0.5960\n",
            "Epoch 198: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.7796 - loss: 0.5960 - val_accuracy: 0.6983 - val_loss: 0.8016\n",
            "Epoch 199/200\n",
            "\u001b[1m2481/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7773 - loss: 0.5929\n",
            "Epoch 199: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7773 - loss: 0.5929 - val_accuracy: 0.6950 - val_loss: 0.8074\n",
            "Epoch 200/200\n",
            "\u001b[1m2480/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7750 - loss: 0.5986\n",
            "Epoch 200: val_accuracy did not improve from 0.70465\n",
            "\u001b[1m2485/2485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.7750 - loss: 0.5986 - val_accuracy: 0.6984 - val_loss: 0.7976\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ccc143b2500>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model with checkpointing\n",
        "model1.fit(X_train_smote, y_train_smote,\n",
        "           validation_data=(X_test.reshape(X_test.shape[0], 1, 100), y_test),  # Reshape X_test for LSTM\n",
        "           epochs=200,\n",
        "           callbacks=[checkpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kndm9ydzQml5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rcdjPwNbhOv2",
        "outputId": "b19cc41b-84cc-47af-a682-12297dc7bb4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.42.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.112.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.6.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.42.0-py3-none-any.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.6.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.2-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.2\n",
            "    Uninstalling tomlkit-0.13.2:\n",
            "      Successfully uninstalled tomlkit-0.13.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.112.2 ffmpy-0.4.0 gradio-4.42.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.9 ruff-0.6.2 semantic-version-2.10.0 starlette-0.38.2 tomlkit-0.12.0 uvicorn-0.30.6 websockets-12.0\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a1a2559bff73bd2e76.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a1a2559bff73bd2e76.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Load the saved NLP model\n",
        "from tensorflow.keras.models import load_model\n",
        "!pip install gradio\n",
        "\n",
        "import gensim\n",
        "import gradio as gr\n",
        "model1 = load_model('/content/drive/MyDrive/modelnlp.keras')\n",
        "# Load the Word2Vec model\n",
        "word2vec_model = gensim.models.Word2Vec.load('/content/drive/MyDrive/word2vec_model')\n",
        "# Download required NLTK data\n",
        "!pip install nltk\n",
        "from nltk import word_tokenize, WordNetLemmatizer, download, corpus\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import gensim\n",
        "from nltk import word_tokenize, WordNetLemmatizer, download, corpus\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "# Initialize lemmatizer and stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Manually define the class labels\n",
        "class_labels = ['Anxiety', 'Normal', 'Depression', 'Suicidal', 'Stress', 'Bipolar', 'Personality disorder']\n",
        "encoder = LabelEncoder()\n",
        "encoder.classes_ = np.array(class_labels)\n",
        "\n",
        "# Function to remove extra spaces\n",
        "def remove_extra_spaces(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stopwords]\n",
        "\n",
        "# Function to convert text to Word2Vec vectors\n",
        "def text_to_word2vec(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    vectors = [word2vec_model.wv[token] for token in lemmatized_tokens if token in word2vec_model.wv]\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros(word2vec_model.vector_size)\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "# Preprocessing and converting to Word2Vec vectors\n",
        "def preprocess_and_vectorize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = remove_extra_spaces(text)  # Remove extra spaces\n",
        "    vector = text_to_word2vec(text)\n",
        "    return np.reshape(vector, (1, 1, word2vec_model.vector_size))  # Reshape for model input\n",
        "\n",
        "# Prediction function with error handling\n",
        "def predict(text):\n",
        "    # Apply preprocessing and vectorization\n",
        "    preprocessed_vector = preprocess_and_vectorize(text)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model1.predict(preprocessed_vector)\n",
        "\n",
        "    # Get predicted class index\n",
        "    predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "    # Map index to class label\n",
        "    predicted_class_label = encoder.classes_[predicted_class_index]\n",
        "\n",
        "    return predicted_class_label\n",
        "\n",
        "\n",
        "# Create Gradio interface\n",
        "gr_interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",  # Output will be the predicted class label\n",
        "    title=\"Mental Status Prediction\",\n",
        "    description=\"How you are feeling\"\n",
        ")\n",
        "# Launch Gradio app\n",
        "gr_interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndC1zYYEH9Gn"
      },
      "outputs": [],
      "source": [
        "# Anxiety:\n",
        "# \"My thoughts are spiraling, and I can't seem to calm the constant sense of dread.\"\n",
        "\n",
        "# Normal:\n",
        "# \"I feel balanced and present, able to take on whatever comes my way with ease.\"\n",
        "\n",
        "# Depression:\n",
        "# \"Everything feels heavy, like I'm sinking into a darkness I can’t escape.\"\n",
        "\n",
        "# Suicidal:\n",
        "# \"The pain feels overwhelming, and I struggle to see any light or reason to continue.\"\n",
        "\n",
        "# Stress:\n",
        "# \"The weight of everything is pressing down on me, and I feel like I’m on the verge of breaking.\"\n",
        "\n",
        "# Bipolar:\n",
        "# \"One moment, I'm bursting with energy and ideas, the next, I'm trapped in a pit of exhaustion and hopelessness.\"\n",
        "\n",
        "# Personality Disorder:\n",
        "# \"I feel fractured, like my sense of self shifts from one extreme to another, leaving me confused and lost.\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}